{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying relational learning to time series: Occupancy detection\n",
    "\n",
    "The purpose of this notebook is to demonstrate how relational learning can be applied to a simple time series data set.\n",
    "\n",
    "Many data scientists are surprised to learn that **relational learning is great for time series**.\n",
    "\n",
    "But once you think about it, it is not that surprising. When we handle time series data, we usually extract features like this:\n",
    "\n",
    "1. **Aggregations over time**, such as the average value of some column for the last 3 days.\n",
    "\n",
    "2. **Seasonal effects**, such as today is a Wednesday, so let's get the average value for the last four Wednesdays.\n",
    "\n",
    "3. **Lag variables**, such as get the value of some column from two hours ago.\n",
    "\n",
    "Using relational learning, we can **extract all of these features automatically**. We can then apply state-of-the-art machine learning algorithms, like xgboost. Usually, this performs **better than traditional time series analysis**.\n",
    "\n",
    "To show how relational learning can be used for time series, we apply a relational learning algorithm to a very **simple public domain time series dataset**. You can download the dataset from [here](http://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+) (but you don't have to - downloading the data is integrated in this notebook).\n",
    "\n",
    "As a **reference and benchmark**, we use [this paper](http://www.worldresearchlibrary.org/up_proc/pdf/568-148612088816-20.pdf):\n",
    "\n",
    "* Accurate occupancy detection of an office room from light, temperature, humidity and CO2 measurements using statistical learning models. Luis M. Candanedo, Veronique Feldheim. Energy and Buildings. Volume 112, 15 January 2016, Pages 28-39.\n",
    "\n",
    "This notebook is **completely self-contained**. You can just run it to reproduce our results. You will need [getML](https://getml.com/product) in order to do so. You can [download it for free](https://getml.com/product).\n",
    "\n",
    "If you want to learn more about getML, check out the [official documentation](https://docs.getml.com/latest/).\n",
    "\n",
    "## The challenge\n",
    "\n",
    "The challenge is simple: We want to **predict whether an office room is occupied** at a given moment in time using sensor data. The data is measured about **once a minute**.\n",
    "\n",
    "Here are the available columns:\n",
    "\n",
    "* Date, year-month-day hour:minute:second\n",
    "* Temperature, in Celsius\n",
    "* Relative Humidity, %\n",
    "* Light, in Lux\n",
    "* CO2, in ppm\n",
    "* Humidity Ratio, Derived quantity from temperature and relative humidity, in kgwater-vapor/kg-air\n",
    "* **Target**: Occupancy, 0 or 1, 0 for not occupied, 1 for occupied status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib import request\n",
    "\n",
    "import getml\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "This notebook is completely self-contained. So we will help you get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [\n",
    "    'datatraining.txt',\n",
    "    'datatest.txt',\n",
    "    'datatest2.txt'\n",
    "]\n",
    "\n",
    "for fname in fnames:\n",
    "    if not os.path.exists(fname):\n",
    "        fname, res = request.urlretrieve(\n",
    "            \"https://raw.githubusercontent.com/LuisM78/Occupancy-detection-data/master/\" + fname, \n",
    "            fname\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set the project.\n",
    "\n",
    "In getML, every data frame and model is **tied to a project**. If you change the project, then the memory is flushed and all unsaved changes are lost (but don't worry, models are saved automatically)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new project 'occupancy_detection'\n"
     ]
    }
   ],
   "source": [
    "getml.engine.set_project('occupancy_detection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "First, we **load the data into pandas**. There are other ways to do this, but this is such a small data set that pandas seems the easiest approach. \n",
    "\n",
    "The data set is conveniently separated into a training, a validation and a testing set. This allows us to **directly benchmark our results** against the results of the original paper.\n",
    "\n",
    "This is what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>Occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-04 17:51:00</td>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>426.0</td>\n",
       "      <td>721.250000</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-04 17:51:59</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>429.5</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-04 17:53:00</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>426.0</td>\n",
       "      <td>713.500000</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-04 17:54:00</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>708.250000</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-02-04 17:55:00</td>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>704.500000</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8139</th>\n",
       "      <td>2015-02-10 09:29:00</td>\n",
       "      <td>21.05</td>\n",
       "      <td>36.0975</td>\n",
       "      <td>433.0</td>\n",
       "      <td>787.250000</td>\n",
       "      <td>0.005579</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>2015-02-10 09:29:59</td>\n",
       "      <td>21.05</td>\n",
       "      <td>35.9950</td>\n",
       "      <td>433.0</td>\n",
       "      <td>789.500000</td>\n",
       "      <td>0.005563</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>2015-02-10 09:30:59</td>\n",
       "      <td>21.10</td>\n",
       "      <td>36.0950</td>\n",
       "      <td>433.0</td>\n",
       "      <td>798.500000</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>2015-02-10 09:32:00</td>\n",
       "      <td>21.10</td>\n",
       "      <td>36.2600</td>\n",
       "      <td>433.0</td>\n",
       "      <td>820.333333</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8143</th>\n",
       "      <td>2015-02-10 09:33:00</td>\n",
       "      <td>21.10</td>\n",
       "      <td>36.2000</td>\n",
       "      <td>447.0</td>\n",
       "      <td>821.000000</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8143 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date  Temperature  Humidity  Light         CO2  \\\n",
       "1     2015-02-04 17:51:00        23.18   27.2720  426.0  721.250000   \n",
       "2     2015-02-04 17:51:59        23.15   27.2675  429.5  714.000000   \n",
       "3     2015-02-04 17:53:00        23.15   27.2450  426.0  713.500000   \n",
       "4     2015-02-04 17:54:00        23.15   27.2000  426.0  708.250000   \n",
       "5     2015-02-04 17:55:00        23.10   27.2000  426.0  704.500000   \n",
       "...                   ...          ...       ...    ...         ...   \n",
       "8139  2015-02-10 09:29:00        21.05   36.0975  433.0  787.250000   \n",
       "8140  2015-02-10 09:29:59        21.05   35.9950  433.0  789.500000   \n",
       "8141  2015-02-10 09:30:59        21.10   36.0950  433.0  798.500000   \n",
       "8142  2015-02-10 09:32:00        21.10   36.2600  433.0  820.333333   \n",
       "8143  2015-02-10 09:33:00        21.10   36.2000  447.0  821.000000   \n",
       "\n",
       "      HumidityRatio  Occupancy  \n",
       "1          0.004793          1  \n",
       "2          0.004783          1  \n",
       "3          0.004779          1  \n",
       "4          0.004772          1  \n",
       "5          0.004757          1  \n",
       "...             ...        ...  \n",
       "8139       0.005579          1  \n",
       "8140       0.005563          1  \n",
       "8141       0.005596          1  \n",
       "8142       0.005621          1  \n",
       "8143       0.005612          1  \n",
       "\n",
       "[8143 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatraining_pandas = pd.read_csv('datatraining.txt')\n",
    "datatest_pandas = pd.read_csv('datatest.txt')\n",
    "datatest2_pandas = pd.read_csv('datatest2.txt')\n",
    "\n",
    "datatraining_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded the data into pandas, we now **load it into getML**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = getml.data.DataFrame.from_pandas(datatraining_pandas, name='data_train')\n",
    "\n",
    "data_validate = getml.data.DataFrame.from_pandas(datatest_pandas, name='data_validate')\n",
    "\n",
    "data_test = getml.data.DataFrame.from_pandas(datatest2_pandas, name='data_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotating data\n",
    "\n",
    "We need to assign **roles**.\n",
    "\n",
    "To learn more about what roles do and why we need them, check out the [official documentation](https://docs.getml.com/latest/user_guide/annotating_data/annotating_data.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [data_train, data_validate, data_test]:\n",
    "    df.set_role(['Occupancy'], getml.data.roles.target)\n",
    "    df.set_role(['Temperature', 'Humidity', 'Light', 'CO2', 'HumidityRatio'], getml.data.roles.numerical)\n",
    "    df.set_role(['date'], getml.data.roles.time_stamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time stamps in getML are always interpreted as **days**. But in this data set, the data is measured every minute. To make this a bit more readable, we define a simple helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minutes(x):\n",
    "    \"\"\"Helper function to convert minutes to days.\n",
    "    \n",
    "    Note that there are 60 minutes in an hour and 24 hours in a day.\n",
    "    \"\"\"\n",
    "    return x / 60.0 / 24.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to make this data set relational:\n",
    "\n",
    "First, we add a **dummy join key**. The entire data set is actually one big time series - most other time series data seta contain more than just one series. So we can just add a constant value to the entire data frame.\n",
    "\n",
    "Second, we add an **upper time stamp**. Upper time stamps impose an **upper limit** on all of our aggregations. In this case, we only want to aggregate the data over the **last 10 minutes**.\n",
    "\n",
    "In effect, a simplified version of what we are going for is this:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE FEATURE_1 AS\n",
    "SELECT SOME_AGGREGATION( t2.some_column ) AS feature_1,\n",
    "       t1.join_key,\n",
    "       t1.date\n",
    "FROM data_train t1\n",
    "LEFT JOIN data_train t2\n",
    "ON t1.join_key = t2.join_key\n",
    "WHERE (...some conditions...) \n",
    "AND t2.date <= t1.date\n",
    "AND t2.upper_time_stamp > t1.date \n",
    "GROUP BY t1.join_key,\n",
    "         t1.date;```\n",
    "         \n",
    "This means that the feature engineering algorithm can only **aggregate values from the past** (```t2.date <= t1.date```), and only from the **last 10 minutes** (```t2.upper_time_stamp > t1.date```).\n",
    "\n",
    "Upper time stamps are a but tricky to understand at first, but once you've wrapped your head around them, they are very powerful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [data_train, data_validate, data_test]:\n",
    "    df.add(np.ones(len(df)), 'join_key', getml.data.roles.join_key)\n",
    "    df.add(df[\"date\"] + minutes(10),  \"upper_time_stamp\", getml.data.roles.time_stamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the data model\n",
    "\n",
    "We need to build the data model. We do so by simply **joining the table onto itself** and imposing the conditions we have just discussed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = data_train.to_placeholder()\n",
    "\n",
    "peripheral = data_train.to_placeholder()\n",
    "\n",
    "population.join(\n",
    "    peripheral, \n",
    "    join_key=\"join_key\", \n",
    "    time_stamp=\"date\",\n",
    "    upper_time_stamp=\"upper_time_stamp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the hyperparameters\n",
    "\n",
    "We use a [MultirelModel](https://docs.getml.com/latest/api/getml.models.MultirelModel.html) for generating the features and an [XGBoostClassifier](https://docs.getml.com/latest/api/getml.predictors.XGBoostClassifier.html#getml.predictors.XGBoostClassifier) for feature selection and prediction.\n",
    "\n",
    "We really don't spend a lot of effort on the hyperparameters and largely go with the default values. The only exception is that we add some regularization to the XGBoostClassifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selector = getml.predictors.XGBoostClassifier(reg_lambda=500)\n",
    "\n",
    "predictor = getml.predictors.XGBoostClassifier(reg_lambda=500)\n",
    "\n",
    "model = getml.models.MultirelModel(\n",
    "        num_features=30,\n",
    "        population=population,\n",
    "        peripheral=[peripheral],\n",
    "        loss_function=getml.models.loss_functions.CrossEntropyLoss(),\n",
    "        feature_selector=feature_selector,\n",
    "        predictor=predictor,\n",
    "        seed=1706\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model\n",
    "\n",
    "We now fit the model. This should take well under one minute, depending on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data. Features are now being trained...\n",
      "Trained model.\n",
      "Time taken: 0h:0m:27.504409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = model.fit(\n",
    "    population_table=data_train,\n",
    "    peripheral_tables=[data_train]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring the model\n",
    "\n",
    "Let's see how well we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (training): 0.99460\n",
      "AUC (training): 0.99899\n",
      "\n",
      "Accuracy (testing): 0.99210\n",
      "AUC (testing): 0.99743\n"
     ]
    }
   ],
   "source": [
    "in_sample = model.score(population_table=data_train,\n",
    "              peripheral_tables=[data_train]\n",
    "             )\n",
    "out_of_sample = model.score(population_table=data_test,\n",
    "              peripheral_tables=[data_test]\n",
    "             )\n",
    "\n",
    "print(\"Accuracy (training): {:.5f}\\nAUC (training): {:.5f}\\n\\nAccuracy (testing): {:.5f}\\nAUC (testing): {:.5f}\".format(\n",
    "    in_sample['accuracy'][0], in_sample['auc'][0], out_of_sample['accuracy'][0], out_of_sample['auc'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [original paper](http://www.worldresearchlibrary.org/up_proc/pdf/568-148612088816-20.pdf), the authors tried several approaches. The **best out-of-sample values** of all the approaches they tried are the following:\n",
    "\n",
    "* Accuracy (testing): 0.99061\n",
    "* AUC (testing): 0.99574\n",
    "\n",
    "Note that our results **outperform the best approach from the original paper**, both in terms of accuracy as well as AUC. This is despite the fact that we arguably **did not spend a lot of time on this**.\n",
    "\n",
    "This demonstrates that relational learning is a **powerful tool for time series**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studying the features\n",
    "\n",
    "It is always a good idea to study the features the relational learning algorithm has extracted.\n",
    "\n",
    "We can do so in the [feature view](https://docs.getml.com/latest/user_guide/getml_suite/monitor/models.html#feature-view).\n",
    "\n",
    "We first look at the **most important feature**. This feature is negatively correlated with the target (a correlation coefficient of -92%) and accounts for **almost 64% of the total predictive power**.\n",
    "\n",
    "![alt text](feature-1.png \"FEATURE_1\")\n",
    "\n",
    "So what is it? Let's take a look at the SQL code:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE FEATURE_1 AS\n",
    "SELECT MIN( t1.date - t2.date ) AS feature_1,\n",
    "       t1.join_key,\n",
    "       t1.date\n",
    "FROM (\n",
    "     SELECT *,\n",
    "            ROW_NUMBER() OVER ( ORDER BY join_key, date ASC ) AS rownum\n",
    "     FROM data_train\n",
    ") t1\n",
    "LEFT JOIN data_train t2\n",
    "ON t1.join_key = t2.join_key\n",
    "WHERE (\n",
    "   ( t2.Light > 458.172840 AND t1.Light > 502.583333 AND t2.Humidity > 26.403623 AND t2.Light <= 684.267857 )\n",
    "OR ( t2.Light > 458.172840 AND t1.Light <= 502.583333 AND t2.Temperature > 22.264286 AND t2.Temperature > 22.315385 )\n",
    "OR ( t2.Light > 458.172840 AND t1.Light <= 502.583333 AND t2.Temperature <= 22.264286 )\n",
    "OR ( t2.Light <= 458.172840 AND t1.date - t2.date > 0.006185 )\n",
    "OR ( t2.Light <= 458.172840 AND t1.date - t2.date <= 0.006185 AND t1.Light > 365.987395 )\n",
    "OR ( t2.Light <= 458.172840 AND t1.date - t2.date <= 0.006185 AND t1.Light <= 365.987395 AND t1.Humidity > 37.597339 )\n",
    ") AND t2.date <= t1.date\n",
    "AND ( t2.upper_time_stamp > t1.date OR t2.upper_time_stamp IS NULL )\n",
    "GROUP BY t1.rownum,\n",
    "         t1.join_key,\n",
    "         t1.date;\n",
    "```\n",
    "\n",
    "Simply speaking, this feature checks **how long ago the light was last switched on**. If that was relatively recent, it is more likely that the room is occupied. There are other factors, such as temperature and humidity that come into the equation as well, but simply speaking this is what the feature does.\n",
    "\n",
    "The **second most important feature** has a strong positive correlation with the target (88%) and accounts for **13% of the predictive power**:\n",
    "\n",
    "![alt text](feature-2.png \"FEATURE_2\")\n",
    "\n",
    "```sql\n",
    "CREATE TABLE FEATURE_2 AS\n",
    "SELECT MAX( t2.Temperature ) AS feature_2,\n",
    "       t1.join_key,\n",
    "       t1.date\n",
    "FROM (\n",
    "     SELECT *,\n",
    "            ROW_NUMBER() OVER ( ORDER BY join_key, date ASC ) AS rownum\n",
    "     FROM data_train\n",
    ") t1\n",
    "LEFT JOIN data_train t2\n",
    "ON t1.join_key = t2.join_key\n",
    "WHERE (\n",
    "   ( t1.Light > 365.007463 AND t1.Temperature > 22.625156 AND t1.Temperature > 22.659000 AND t1.Light <= 522.805556 )\n",
    "OR ( t1.Light > 365.007463 AND t1.Temperature > 22.625156 AND t1.Temperature <= 22.659000 AND t2.Temperature <= 22.622222 )\n",
    "OR ( t1.Light > 365.007463 AND t1.Temperature <= 22.625156 AND t1.Humidity > 18.924881 AND t1.date - t2.date <= 0.000661 )\n",
    ") AND t2.date <= t1.date\n",
    "AND ( t2.upper_time_stamp > t1.date OR t2.upper_time_stamp IS NULL )\n",
    "GROUP BY t1.rownum,\n",
    "         t1.join_key,\n",
    "         t1.date;\n",
    "\n",
    "```\n",
    "\n",
    "Simply speaking, this feature is based on **the maximum temperature, given some other conditions**. The higher the temperature, the more likely it is that the room is occupied.\n",
    "\n",
    "It is very unlikely that you would have written **features like this manually**. You might have written simpler features that are similar to this, but you have had to put in **more effort**.\n",
    "\n",
    "Also note that some of the features are **columns directly taken from the original table**, such as *Light* and *CO2*. But these columns are **less correlated** and **less important** than the generated features, as we can see from the [model view](https://docs.getml.com/latest/user_guide/getml_suite/monitor/models.html#model-view).\n",
    "\n",
    "\n",
    "![alt text](model-view.png \"Model View\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates that **relational learning is a powerful tool for time series**. We able to outperform the benchmarks for a scientific paper on a simple public domain time series data set using **relatively little effort**.\n",
    "\n",
    "If you want to learn more, about getML, check out the [official documentation](https://getml.com/product).\n",
    "\n",
    "To reproduce the results in this notebook, you can [download getML for free](https://docs.getml.com/latest/).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
