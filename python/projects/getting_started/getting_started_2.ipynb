{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Started with getML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getML adds automated feature engineering on relational data and time series to AutoML. In this guide you will learn the basic steps and commands to tackle your data science projects using the Python API. Please refer to our [installation instructions](https://docs.get.ml/latest/tutorial/installation.html) for installing getML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting a new project\n",
    "\n",
    "After you've successfully [installed](https://docs.get.ml/latest/tutorial/installation.html) getML, you have to launch it by executing the `run` script in the getML folder or double-clicking the application icon (depening on your operating system). This launches the getML engine. The engine is written in C++ for maximum performance and is responsible for all the heavy lifting. You control it via the Python API.\n",
    "\n",
    "Before diving into the actual project, you need to log into the engine. This happens in the getML Monitor, the frontend to the engine. If you open the browser of your choice an visit http://localhost:1709/ you'll see the following login screen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![monitor-login](img/monitor-login.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click 'create new account' and follow the steps indicated by the monitor. After you've activated your account by clicking the link in the activation E-mail you're ready to go. In principle, you can run the entire analysis only from Python. We will, however, visit the monitor from time to time in order to see what is going on in the engine and to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getml.engine as engine\n",
    "engine.set_project('getting_started')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Staging the data\n",
    "\n",
    "For the sake of simpliciy, we will use an artificial dataset in this tutorial that only consits of 2 tables. The population table and one peripheral table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getml.datasets import make_numerical\n",
    "population_table, peripheral_table = make_numerical(\n",
    "    n_rows_population=500,\n",
    "    n_rows_peripheral=100000,\n",
    "    random_state=1709\n",
    ")\n",
    "\n",
    "display(population_table, peripheral_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The population table contains one numerical variable in `column_01`, an unique integer `join_key`, a `time_stamp`, and the `targets` variable that we want to predict in the follwoing. The peripheral table also contains one numerical variable in `column_01`, an integer `join_key` that allows attributon of each row to a row in the population table and a `time_stamp`.\n",
    "\n",
    "The first step of every analysis is to load the data into the getML engine. In order to optimize performance of the automated feature engineering algorithm, the role of each column has to be defined beforehand. The role of a column tells the algorithm weather a column is to be treated as numerical, categorical or discrete or weather it has a special meaning. It can e.g. represent a join key, a time stamp or the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peripheral_on_engine = engine.DataFrame(\n",
    "    name=\"PERIPHERAL\",\n",
    "    join_keys=[\"join_key\"],\n",
    "    numerical=[\"column_01\"],\n",
    "    time_stamps=[\"time_stamp\"]\n",
    ")\n",
    "\n",
    "peripheral_on_engine.send(peripheral_table)\n",
    "\n",
    "population_on_engine = engine.DataFrame(\n",
    "    name=\"POPULATION\",\n",
    "    join_keys=[\"join_key\"],\n",
    "    numerical=[\"column_01\"],\n",
    "    time_stamps=[\"time_stamp\"],\n",
    "    targets=[\"targets\"]\n",
    ")\n",
    "\n",
    "population_on_engine.send(population_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you go back to the monitor (in your browser) and click on the 'Data Frames' tab in the navigation menu, you should see the following screen\n",
    "\n",
    "![monitor-dataframe](img/monitor-dataframe.png)\n",
    "\n",
    "Two Data Frames, the population table with 500 rows and the periphera table with 100000 rows have been uploaded to the engine. You can click on each table to see the data and the roles you have define for each column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a model\n",
    "\n",
    "The next step is finding features in the data that allow us to predict the target variable in the population table. This is achieved using a MultirelModel. This model is responsible for the entire process from feature engineering to prediciting the target variable based on the generated features. The MultirelModel requires a predefined data model with all joins defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getml import models\n",
    "\n",
    "population_placeholder = models.Placeholder(\n",
    "    name=\"POPULATION\",\n",
    "    numerical=[\"column_01\"],\n",
    "    join_keys=[\"join_key\"],\n",
    "    time_stamps=[\"time_stamp\"],\n",
    "    targets=[\"targets\"]\n",
    ")\n",
    "\n",
    "peripheral_placeholder = models.Placeholder(\n",
    "    name=\"PERIPHERAL\",\n",
    "    numerical=[\"column_01\"],\n",
    "    join_keys=[\"join_key\"],\n",
    "    time_stamps=[\"time_stamp\"]\n",
    ")\n",
    "\n",
    "population_placeholder.join(peripheral_placeholder,\n",
    "                            \"join_key\",\n",
    "                            \"time_stamp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the Model. On top of the placeholder for the Data Frames it requires a list of aggregations to select from when building features. You also have to define a loss function, a predictor and some hyperparameters like the number of features you want to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getml import predictors\n",
    "from getml import aggregations\n",
    "from getml import loss_functions\n",
    "\n",
    "model = models.MultirelModel(\n",
    "    name='getting_started_model',\n",
    "    aggregation=[\n",
    "        aggregations.Count,\n",
    "        aggregations.Sum\n",
    "    ],\n",
    "    population=population_placeholder,\n",
    "    peripheral=[peripheral_placeholder],\n",
    "    loss_function=loss_functions.SquareLoss(),\n",
    "    predictor=predictors.LinearRegression(),\n",
    "    num_features=10,\n",
    ").send()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a model\n",
    "\n",
    "When fitting the model you have to pass it the actual data tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(\n",
    "    population_table=population_on_engine,\n",
    "    peripheral_tables=[peripheral_on_engine]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this step the model is available in the monitor in the 'Models' tab. Select the 'getting_started_model' in order to see the following screen.\n",
    "\n",
    "![monitor-model](img/monitor-model.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see the 10 features trained by the MultirelModel sorted by their importance. The most significant feature is `feature_2` with an importance of \t`0.6476`. Below you also see the data model that was defined for that model. We will come to the graphs that are empty at the moment in a second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring the model\n",
    "\n",
    "Let's generate a new population table in order to see how well the trained model performs. The available score are mean absolute error, root mean squared error and the square correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_table_score, peripheral_table_score = make_numerical(\n",
    "    n_rows_population=200,\n",
    "    n_rows_peripheral=8000,\n",
    "    random_state=1710\n",
    ")\n",
    "\n",
    "scores = model.score(\n",
    "    population_table=population_table_score,\n",
    "    peripheral_tables=[peripheral_table_score]\n",
    ")\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is able to predict the target variable in the newly generated dataset very accurately. The scores will automatically appear in the getML monitor as well as the correlation of each feature with the target.\n",
    "\n",
    "![monitor-model](img/monitor-score.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions\n",
    "\n",
    "You can also make predictions using the model you have just trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_table_predict, peripheral_table_predict = make_numerical(\n",
    "    n_rows_population=200,\n",
    "    n_rows_peripheral=8000,\n",
    "    random_state=1711\n",
    ")\n",
    "\n",
    "\n",
    "yhat = model.predict(\n",
    "    population_table=population_table_predict,\n",
    "    peripheral_tables=[peripheral_table_predict]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting features\n",
    "\n",
    "Of course you can also extract the features for a specifig dataset in order to insert them into another machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.transform(\n",
    "    population_table=population_table_predict,\n",
    "    peripheral_tables=[peripheral_table_predict]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see the SQL code for each feature you can do so by clicking on the feature in the monitor or calling the `to_sql` method on the MultirelModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.to_sql())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definiton of `feature_2` is\n",
    "\n",
    "```\n",
    "CREATE TABLE FEATURE_2 AS\n",
    "SELECT COUNT( * ) AS feature_2,\n",
    "       t1.join_key,\n",
    "       t1.time_stamp\n",
    "FROM (\n",
    "     SELECT *,\n",
    "            ROW_NUMBER() OVER ( ORDER BY join_key, time_stamp ASC ) AS rownum\n",
    "     FROM POPULATION\n",
    ") t1\n",
    "LEFT JOIN PERIPHERAL t2\n",
    "ON t1.join_key = t2.join_key\n",
    "WHERE (\n",
    "   ( t1.time_stamp - t2.time_stamp <= 0.499323 )\n",
    ") AND t2.time_stamp <= t1.time_stamp\n",
    "GROUP BY t1.rownum,\n",
    "         t1.join_key,\n",
    "         t1.time_stamp;\n",
    "\n",
    "```\n",
    "\n",
    "This is almost exactly the definition of the target variable in the artificial dataset we have generated in the beginning. getML extracted this defintion completely autonomosly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "This guide has shown you the very basics of getML. But there's more\n",
    "\n",
    "* If you're want to find out more about getML in general, head over to the [webpage](https://get.ml)\n",
    "* If you're intersted in more advanced projects on real world datasets, you can find examples in the [projects section]() of the documentation.\n",
    "* If you're curious about other features of getML, go to our [user guide](https://docs.get.ml).\n",
    "\n",
    "Also, don't hesitate to [contact us](https://get.ml/contact/lets-talk) with your feedback."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
