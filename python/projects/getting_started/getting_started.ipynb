{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This short blog post gets you started with **getML**. You will learn\n",
    "the basic steps and commands to tackle your data science project using\n",
    "its Python API. The underlying Python script can be accessed\n",
    "[here](consumer_expenditure.py).\n",
    "\n",
    "# Motivation / Problem\n",
    "\n",
    "To make our short introduction as realistic as possible, we will start\n",
    "from a public-domain real-world data set. Let's pretend we are a\n",
    "company selling and shipping a large portfolio of different\n",
    "products. To both improve user experience and increase revenue, we\n",
    "want to offer a special wrapping in case a product was bought as a\n",
    "gift. But how to inform the costumers in question about our new\n",
    "service without annoying everyone else?\n",
    "\n",
    "The most prolific approach to solve such kind of problems is Machine\n",
    "Learning. We will use it on the consumer expenditure public-use\n",
    "microdata provided by the [U.S. Bureau of Labor\n",
    "Statistics](https://www.bls.gov/cex/pumd_data.htm) to predict whether\n",
    "a product is bought as a gift or not.\n",
    "\n",
    "\n",
    "# Prerequisites\n",
    "\n",
    "## Install getML\n",
    "\n",
    "But first of all you have to install **getML**. Just go to our [web\n",
    "page](https://get.ml), browse to the download page, choose the track\n",
    "that fits you most, and unpack the tarball we provide. That's it.\n",
    "\n",
    "## Run getML\n",
    "\n",
    "To run the application, all you need to do is enter the unpacked\n",
    "tarball and execute the `run` script."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "./run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This starts up the **getML engine**, which was written in C++ for\n",
    "efficiency and takes care of all the heavy lifting, and the **getML\n",
    "monitor**, which serves as a convenient user interface. \n",
    "\n",
    "Next, you need to **log into the engine**. Open the up the web browser\n",
    "of your choice and enter `localhost:1709` in the address bar. You will\n",
    "access a *local* HTTP server run by the monitor, which will ask you to\n",
    "enter your credentials or to create a new account. Please note that\n",
    "this account is *not* a local one but the one you set up via our\n",
    "homepage. Thus, you also need a working internet connection to run the\n",
    "software.\n",
    "\n",
    "## Install the getML Python3 API\n",
    "\n",
    "Bundled with the **getML** binary you can also find its Python3 API. To\n",
    "install it, use the following commands"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cd python\n",
    "python3 setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data\n",
    "\n",
    "Finally, we need some data to work with. You have two\n",
    "options here.\n",
    "\n",
    "1. Get our cleaned and preprocessed [version](/data/consumer_expenditures) to start\n",
    "right away (assumed in the remainder of the post).\n",
    "2. Download the [original\n",
    "dataset](https://www.bls.gov/cex/pumd_data.htm) (diary15) and perform\n",
    "the preprocessing yourself using [this](/data/consumer_expenditures/raw/convert_CE_data.py) cleaning\n",
    "script.\n",
    "\n",
    "# Staging the data\n",
    "\n",
    "With the preprocessing already done we will start by setting a new\n",
    "project in the **getML** engine and loading the prepared tables into\n",
    "the Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import getml.engine as engine\n",
    "\n",
    "engine.set_project(\"gettingStarted\")\n",
    "\n",
    "# Location inside this repository the data is kept.\n",
    "source_path = os.path.join(os.getcwd(), \"../../../data/consumer_expenditures/\")\n",
    "\n",
    "CE_population_training = pd.read_csv(os.path.join(source_path, \"CE_population_training.csv\"))\n",
    "CE_population_validation = pd.read_csv(os.path.join(source_path, \"CE_population_validation.csv\"))\n",
    "CE_peripheral = pd.read_csv(os.path.join(source_path, \"CE_peripheral.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the automated feature engineering to get the most out of\n",
    "the data, we have to provided some additional information about its\n",
    "content. If a column contains e.g. the type of a product encoded in\n",
    "integers, operations like comparisons, summation, or the extraction\n",
    "the maximum would most probably make no sense. It, therefore, needs to\n",
    "be of recognized as *categorical* instead of *discrete*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL = [\n",
    "    \"UCC\",\n",
    "    \"UCC1\",\n",
    "    \"UCC2\",\n",
    "    \"UCC3\",\n",
    "    \"UCC4\",\n",
    "    \"UCC5\"]\n",
    "\n",
    "DISCRETE = [\"EXPNYR\"]\n",
    "\n",
    "JOIN_KEYS = [\n",
    "    \"NEWID\",\n",
    "    \"BASKETID\"]\n",
    "\n",
    "NUMERICAL = [\"COST\"]\n",
    "\n",
    "TARGETS = [\"TARGET\"]\n",
    "\n",
    "TIME_STAMPS = [\n",
    "    \"TIME_STAMP\",\n",
    "    \"TIME_STAMP_SHIFTED\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also assign units to indicate which columns should be\n",
    "compared and to fine-tune their handling. More information about this\n",
    "subject can be found in the [long read](/link/long/) and the [API\n",
    "documentation](https://docs.get.ml)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = dict()\n",
    "\n",
    "units[\"UCC\"] = \"UCC\"\n",
    "units[\"UCC1\"] = \"UCC1\"\n",
    "units[\"UCC2\"] = \"UCC2\"\n",
    "units[\"UCC3\"] = \"UCC3\"\n",
    "units[\"UCC4\"] = \"UCC4\"\n",
    "units[\"UCC5\"] = \"UCC5\"\n",
    "\n",
    "units[\"EXPNYR\"] = \"year, comparison only\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all that additional information in place we can finally construct\n",
    "the `DataFrame`s, which will serve as our handles for the tables\n",
    "stored in the engine. Using the `.send()` method we upload the\n",
    "provided data to the engine and `.save()` ensures the `DataFrame` will\n",
    "persist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population_training = engine.DataFrame(\n",
    "    \"POPULATION_TRAINING\",\n",
    "    join_keys=JOIN_KEYS,\n",
    "    time_stamps=TIME_STAMPS,\n",
    "    categorical=CATEGORICAL,\n",
    "    discrete=DISCRETE,\n",
    "    numerical=NUMERICAL,\n",
    "    targets=TARGETS,\n",
    "    units=units\n",
    ").send(CE_population_training)\n",
    "df_population_training.save()\n",
    "\n",
    "df_population_validation = engine.DataFrame(\n",
    "    \"POPULATION_VALIDATION\",\n",
    "    join_keys=JOIN_KEYS,\n",
    "    time_stamps=TIME_STAMPS,\n",
    "    categorical=CATEGORICAL,\n",
    "    discrete=DISCRETE,\n",
    "    numerical=NUMERICAL,\n",
    "    targets=TARGETS,\n",
    "    units=units\n",
    ").send(CE_population_validation)\n",
    "df_population_validation.save()\n",
    "\n",
    "df_peripheral = engine.DataFrame(\n",
    "    \"PERIPHERAL\",\n",
    "    join_keys=JOIN_KEYS,\n",
    "    time_stamps=TIME_STAMPS,\n",
    "    categorical=CATEGORICAL,\n",
    "    discrete=DISCRETE,\n",
    "    numerical=NUMERICAL,\n",
    "    targets=TARGETS,\n",
    "    units=units\n",
    ").send(CE_peripheral)\n",
    "df_peripheral.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and fitting a model\n",
    "\n",
    "## Placeholders\n",
    "\n",
    "Now, all data is uploaded into the **getML** engine. But to train a model\n",
    "using these tables, we still need a way to represent their relations\n",
    "to each other.\n",
    "\n",
    "We will do so with the concept of placeholders popularized by\n",
    "Tensorflow and linking them using specific columns present in both\n",
    "tables by calling the `.join()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getml.models as models\n",
    "\n",
    "CE_placeholder = models.Placeholder(\"PERIPHERAL\")\n",
    "\n",
    "CE_placeholder2 = models.Placeholder(\"PERIPHERAL\")\n",
    "\n",
    "CE_placeholder.join(\n",
    "    CE_placeholder2,\n",
    "    join_key=\"NEWID\",\n",
    "    time_stamp=\"TIME_STAMP\",\n",
    "    other_time_stamp=\"TIME_STAMP_SHIFTED\"\n",
    ")\n",
    "\n",
    "CE_placeholder.join(\n",
    "    CE_placeholder2,\n",
    "    join_key=\"BASKETID\",\n",
    "    time_stamp=\"TIME_STAMP\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about this steps please have a look at [detailed description](/link/post/).\n",
    "\n",
    "## Feature selector and predictor\n",
    "\n",
    "Apart from our sophisticated algorithm for automated feature\n",
    "engineering in relational data, **getML** has two other main\n",
    "components. \n",
    "\n",
    "The first one is the feature selector, which picks the best set of\n",
    "features from the generated ones. The second is the predictor, which\n",
    "is trained on the features to make predictions and is the component\n",
    "you already know from various other machine learning applications and\n",
    "libraries.\n",
    "\n",
    "For both instances we will use a XGBoost classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getml.predictors as predictors\n",
    "\n",
    "feature_selector = predictors.XGBoostClassifier(\n",
    "    booster=\"gbtree\",\n",
    "    n_estimators=100,\n",
    "    n_jobs=6,\n",
    "    max_depth=7,\n",
    "    reg_lambda=500\n",
    ")\n",
    "\n",
    "predictor = predictors.XGBoostClassifier(\n",
    "    booster=\"gbtree\",\n",
    "    n_estimators=100,\n",
    "    n_jobs=6,\n",
    "    max_depth=7,\n",
    "    reg_lambda=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a model\n",
    "\n",
    "Finally, we have all pieces together to construct the overall\n",
    "model. For details about its arguments, please have a look into the\n",
    "[documentation](https://docs.get.ml). Like a `DataFrame` a model needs\n",
    "to be uploaded to the **getML engine** using the `.send()` method too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getml.aggregations as aggregations\n",
    "import getml.loss_functions as loss_functions\n",
    "\n",
    "model = models.AutoSQLModel(\n",
    "    population=CE_placeholder,\n",
    "    peripheral=[CE_placeholder],\n",
    "    predictor=predictor,\n",
    "    loss_function=loss_functions.CrossEntropyLoss(),\n",
    "    aggregation=[\n",
    "        aggregations.Avg,\n",
    "        aggregations.Count,\n",
    "        aggregations.CountDistinct,\n",
    "        aggregations.CountMinusCountDistinct,\n",
    "        aggregations.Max,\n",
    "        aggregations.Median,\n",
    "        aggregations.Min,\n",
    "        aggregations.Sum\n",
    "    ],\n",
    "    use_timestamps=True,\n",
    "    num_features=70,\n",
    "    max_length=7,\n",
    "    min_num_samples=100,\n",
    "    shrinkage=0.1,\n",
    "    grid_factor=1.0,\n",
    "    regularization=0.0,\n",
    "    round_robin=False,\n",
    "    share_aggregations=0.04,\n",
    "    share_conditions=0.8,\n",
    "    sampling_factor=1.0\n",
    ").send()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model\n",
    "\n",
    "To build the features and train the predictor, all you need to do is\n",
    "to call the `.fit()` method of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data. Features are now being trained...\n",
      "Trained model.\n",
      "Time taken: 0h:5m:52.283375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = model.fit(\n",
    "    population_table=df_population_training,\n",
    "    peripheral_tables=[df_peripheral]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how well it performs, let's evaluate it on the validation set\n",
    "using `.score()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_': [0.9815445341689767], 'auc_': [0.7841916800932824], 'cross_entropy_': [0.07906536350395432]}\n"
     ]
    }
   ],
   "source": [
    "scores = model.score(\n",
    "    population_table=df_population_validation,\n",
    "    peripheral_tables=[df_peripheral]\n",
    ")\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, **getML** supports six different scores: accuracy, AUC\n",
    "(area under the ROC curve), and cross entropy for classification tasks\n",
    "and MAE, RMSE, and R-squared (squared correlation coefficient) for\n",
    "regression. Since determining whether a product was bought as a\n",
    "present is a classification problem, we will recommend the AUC to\n",
    "measure the performance of our model. If you wish, you can gather\n",
    "additional data or tweak the parameters of the `AutoSQLModel` to\n",
    "improve it even further.\n",
    "\n",
    "As soon as you are satisfied with the performance of your model you\n",
    "can use it in production to make predictions on new and unseen data\n",
    "using `.predict()`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
