{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biodegradability\n",
    "\n",
    "In this notebook, we will demonstrate how to **combine relational learning with a Bayesian hyperparameter optimization**.\n",
    "\n",
    "Before we begin, we should note that getML's relational learning algorithms do not require hyperparameter optimization. This sets them apart from some other machine learning algorithms, most notably deep neural networks. If you are working with deep neural networks, you will have to spend a lot of time on optimizing your hyperparameters. getML's algorithms are different: **You will usually already get decent results with the default hyperparameters.** \n",
    "\n",
    "Therefore, you should conduct a hyperparameter optimization when your goal is to **aggressively optimize predictive performance**.\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation\n",
    "\n",
    "* Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new project 'biodegradability'\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import random\n",
    "\n",
    "import getml\n",
    "\n",
    "getml.engine.set_project('biodegradability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish a connection to the remote MariaDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "getml.database.connect_mysql(\n",
    "    host=\"relational.fit.cvut.cz\",\n",
    "    port=3306,\n",
    "    dbname=\"Biodegradability\",\n",
    "    user=\"guest\",\n",
    "    password=\"relational\",\n",
    "    time_formats=['%Y/%m/%d']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all required tables and upload them into the getML engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom = getml.data.DataFrame.from_db('atom','atom')\n",
    "bond = getml.data.DataFrame.from_db('bond','bond')\n",
    "gmember = getml.data.DataFrame.from_db('gmember','gmember')\n",
    "group = getml.data.DataFrame.from_db('group','group')\n",
    "molecule = getml.data.DataFrame.from_db('molecule','molecule')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule.set_role('molecule_id', getml.data.roles.join_key)\n",
    "molecule.set_role('mweight', getml.data.roles.numerical)\n",
    "molecule.set_role('activity', getml.data.roles.numerical)\n",
    "molecule.set_role('logp', getml.data.roles.target)\n",
    "\n",
    "atom.set_role('atom_id', getml.data.roles.join_key)\n",
    "atom.set_role('molecule_id', getml.data.roles.join_key)\n",
    "atom.set_role('type', getml.data.roles.categorical)\n",
    "\n",
    "bond.set_role('atom_id', getml.data.roles.join_key)\n",
    "bond.set_role('atom_id2', getml.data.roles.join_key)\n",
    "bond.set_role('type', getml.data.roles.categorical)\n",
    "\n",
    "gmember.set_role('atom_id', getml.data.roles.join_key)\n",
    "gmember.set_role('group_id', getml.data.roles.join_key)\n",
    "\n",
    "group.set_role('group_id', getml.data.roles.join_key)\n",
    "group.set_role('type', getml.data.roles.categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the molecule data table into training, validation, and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_training = 0.5\n",
    "percentage_validation = 0.25\n",
    "# Add a column containing a shuffled version of the row numbers used to split the data at random.\n",
    "molecule.add(numpy.array(random.sample(range(0, molecule.shape[0]), k=molecule.shape[0])), 'index')\n",
    "\n",
    "molecule_training = molecule.where('molecule_training', \n",
    "                                   molecule['index'] < molecule.shape[0]*percentage_training)\n",
    "molecule_validation = molecule.where('molecule_validation',\n",
    "                                     (molecule['index'] > molecule.shape[0]*percentage_training) &\n",
    "                                   (molecule['index'] < molecule.shape[0]*(percentage_training+percentage_validation)))\n",
    "molecule_testing = molecule.where('molecule_testing', \n",
    "                                   molecule['index'] > molecule.shape[0]*(percentage_training+percentage_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| molecule_id | logp   | mweight   | activity  | index        | \n",
       "| join key    | target | numerical | numerical | unused float | \n",
       "---------------------------------------------------------------\n",
       "| i100_02_7i  | 1.91   | 139.11    | 4.53367   | 231          | \n",
       "| i100_41_4i  | 3.03   | 106.167   | 5.04986   | 177          | \n",
       "| i101_61_1i  | 4.37   | 254.375   | 7.82244   | 175          | \n",
       "| i101_68_8i  | 5.22   | 250.256   | 6.04025   | 167          | \n",
       "| i101_77_9i  | 2.18   | 198.268   | 4.56435   | 178          | \n",
       "| i106_42_3i  | 3.09   | 106.167   | 6.04025   | 223          | \n",
       "| i106_88_7i  | 0.86   | 72.1062   | 6.04025   | 208          | \n",
       "| i106_99_0i  | 2.03   | 54.0914   | 6.04025   | 197          | \n",
       "| i107_05_1i  | 1.93   | 76.5255   | 6.04025   | 190          | \n",
       "| i108_38_3i  | 3.09   | 106.167   | 6.04025   | 240          | \n",
       "| i108_95_2i  | 1.51   | 94.1124   | 3.80666   | 224          | \n",
       "| i110_86_1i  | 0.8    | 79.1015   | 4.56435   | 220          | \n",
       "| i111_42_2i  | -1.71  | 105.136   | 4.51305   | 166          | \n",
       "| i111_44_4i  | 1.56   | 143.012   | 7.82244   | 241          | \n",
       "| i111_90_0i  | -0.69  | 134.174   | 6.04025   | 213          | \n",
       "| i1120_71_4i | -0.28  | 122.143   | 6.04025   | 198          | \n",
       "| i115_29_7i  | 3.84   | 406.927   | 5.2575    | 192          | \n",
       "| i116_06_3i  | 1.36   | 190.266   | 8.42771   | 184          | \n",
       "| i117_84_0i  | 8.54   | 390.56    | 6.04025   | 173          | \n",
       "| i118_96_7i  | 1.99   | 227.132   | 7.82244   | 181          | \n",
       "| ...         | ...    | ...       | ...       | ...          | "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom.save()\n",
    "bond.save()\n",
    "gmember.save()\n",
    "group.save()\n",
    "molecule_training.save()\n",
    "molecule_testing.save()\n",
    "molecule_validation.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_molecule = molecule.to_placeholder()\n",
    "ph_atom = atom.to_placeholder()\n",
    "ph_bond = bond.to_placeholder()\n",
    "ph_gmember = gmember.to_placeholder()\n",
    "ph_group = group.to_placeholder()\n",
    "\n",
    "ph_molecule.join(\n",
    "    ph_atom,\n",
    "    join_key = 'molecule_id'\n",
    ")\n",
    "ph_atom.join(\n",
    "    ph_bond,\n",
    "    join_key = 'atom_id'\n",
    ")\n",
    "ph_atom.join(\n",
    "    ph_bond,\n",
    "    join_key = 'atom_id',\n",
    "    other_join_key = 'atom_id2'\n",
    ")\n",
    "ph_atom.join(\n",
    "    ph_gmember,\n",
    "    join_key = 'atom_id'\n",
    ")\n",
    "ph_gmember.join(\n",
    "    ph_group,\n",
    "    join_key = 'group_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the feature engineerer, feature selector, and predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selector = getml.predictors.XGBoostRegressor(\n",
    "    booster='gblinear',\n",
    "    n_estimators=60,\n",
    "    n_jobs=6,\n",
    "    max_depth=7\n",
    ")\n",
    "\n",
    "predictor = getml.predictors.XGBoostRegressor(\n",
    "    booster='gblinear',\n",
    "    n_estimators=60,\n",
    "    n_jobs=6,\n",
    "    max_depth=7\n",
    ")\n",
    "\n",
    "## -------------------------------------------------------------------\n",
    "\n",
    "## Construct the base model.\n",
    "base_model=getml.models.RelboostModel(\n",
    "    name='base',\n",
    "    population=ph_molecule,\n",
    "    peripheral=[ph_atom, ph_gmember, ph_group, ph_bond],\n",
    "    loss_function=getml.models.loss_functions.SquareLoss(),\n",
    "    num_features=50,\n",
    "    num_subfeatures=10,\n",
    "    feature_selector=feature_selector,\n",
    "    predictor=predictor,\n",
    "    num_threads=3\n",
    ").send()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the initial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data. Features are now being trained...\n",
      "Trained model.\n",
      "Time taken: 0h:0m:20.236894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_model = base_model.fit(\n",
    "    population_table=molecule_training,\n",
    "    peripheral_tables=[atom, gmember, group, bond]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': [0.6256818797420941],\n",
       " 'rmse': [0.9089659525390064],\n",
       " 'rsquared': [0.8510611660062808]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.score(population_table=molecule_validation,\n",
    "                peripheral_tables=[atom, gmember, group, bond])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a Gaussian hyperparameter optimization to find the best possible set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launched hyperparameter optimization...\n"
     ]
    }
   ],
   "source": [
    "## Build a parameter space to search in\n",
    "param_space = dict()\n",
    "\n",
    "param_space[\"max_depth\"] = [1, 10]\n",
    "param_space[\"min_num_samples\"] = [10, 100]\n",
    "param_space[\"num_features\"] = [10, 100]\n",
    "param_space[\"share_selected_features\"] = [0.3, 1.0]\n",
    "param_space[\"shrinkage\"] = [0.01, 0.4]\n",
    "\n",
    "# Any hyperparameters that relate to the predictor\n",
    "# are preceded by \"predictor_\".\n",
    "param_space[\"predictor_n_estimators\"] = [40, 140]\n",
    "param_space[\"predictor_max_depth\"] = [3, 15]\n",
    "param_space[\"predictor_reg_lambda\"] = [0.0, 10.0]\n",
    "\n",
    "## -------------------------------------------------------------------\n",
    "\n",
    "## Start the hyperparameter optimization.\n",
    "gauss_search = getml.hyperopt.GaussianHyperparameterSearch(\n",
    "    model=base_model,\n",
    "    param_space=param_space,\n",
    "    n_iter=120,\n",
    "    ratio_iter=0.8\n",
    ")\n",
    "\n",
    "gauss_search.fit(\n",
    "  population_table_training=molecule_training,\n",
    "  population_table_validation=molecule_validation,\n",
    "  peripheral_tables=[atom, gmember, group, bond]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the model, which resulted in the lowest RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-24T17-07-50-hyperopt-gaussian-relboost-120\n",
      "0.8057118798438392\n"
     ]
    }
   ],
   "source": [
    "res_scores = gauss_search.get_scores()\n",
    "\n",
    "best_model_name = ''\n",
    "best_score = numpy.finfo(numpy.float).max\n",
    "\n",
    "for kkey in res_scores:\n",
    "    if res_scores[kkey]['rmse'][0] < best_score:\n",
    "        best_score = res_scores[kkey]['rmse'][0]\n",
    "        best_model_name = kkey\n",
    "\n",
    "print(best_model_name)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very well, you might say. But how do we know that we didn't just massively overfit to the validation set?\n",
    "\n",
    "Good point. That's why we still have the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test scores base model\n",
      "{'mae': [0.555690715106917], 'rmse': [0.7698695019927322], 'rsquared': [0.8457635624780674]}\n",
      "Test scores best model\n",
      "{'mae': [0.5399810405241117], 'rmse': [0.7067350269328148], 'rsquared': [0.8661407763769823]}\n"
     ]
    }
   ],
   "source": [
    "base_model_testing = base_model.copy('base_model_testing')\n",
    "\n",
    "best_model = getml.models.load_model(best_model_name)\n",
    "best_model_testing = best_model.copy('best_model_testing')\n",
    "\n",
    "scores = base_model_testing.score(\n",
    "    population_table=molecule_testing,\n",
    "    peripheral_tables=[atom, gmember, group, bond]\n",
    ")\n",
    "\n",
    "print(\"Test scores base model:\")\n",
    "print(scores)\n",
    "\n",
    "scores = best_model_testing.score(\n",
    "    population_table=molecule_testing,\n",
    "    peripheral_tables=[atom, gmember, group, bond]\n",
    ")\n",
    "\n",
    "print(\"Test scores best model:\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the evaluation on the testing set still outperforms our base model. Again - not by much. This goes back to our initial statement: Unlike deep neural networks **relational boosting does not require extensive hyperparameter optimization**. You will usually already get decent results with the default parameters or by manually setting some parameters on your own.\n",
    "\n",
    "Hyperparameter optimizations like this are only recommended if your goal is to really optimize your predictive performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
